{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Predict if a property is a good investment based on financial and physical attributes.\n",
    "\n",
    "<b>Target:</b>\n",
    "\n",
    "A binary variable indicating good (1) or bad (0) investment. Define this based on criteria such as a high rent-to-price ratio or a favorable market estimate compared to the listed price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                0\n",
       "City                 0\n",
       "Street               0\n",
       "Zipcode              0\n",
       "Bedroom             14\n",
       "Bathroom            34\n",
       "Area                 0\n",
       "PPSq                 0\n",
       "LotArea            902\n",
       "MarketEstimate    7236\n",
       "RentEstimate      5976\n",
       "Latitude             0\n",
       "Longitude            0\n",
       "ListedPrice          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_estate_data = pd.read_csv(\"./data/real_estate_data.csv\")\n",
    "real_estate_data.describe()\n",
    "\n",
    "# Find any missing data in the dataset.\n",
    "missing_values = real_estate_data.isnull().sum()\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14853,\n",
       " State             0\n",
       " City              0\n",
       " Street            0\n",
       " Zipcode           0\n",
       " Bedroom           0\n",
       " Bathroom          0\n",
       " Area              0\n",
       " PPSq              0\n",
       " LotArea           0\n",
       " MarketEstimate    0\n",
       " RentEstimate      0\n",
       " Latitude          0\n",
       " Longitude         0\n",
       " ListedPrice       0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how much data there is with no null values. This can help us determine if we can simply remove all of the nulls from the dataset.\n",
    "\n",
    "len(real_estate_data.dropna()), real_estate_data.dropna().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1600.0"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average difference of List to Estimate by state.\n",
    "\n",
    "no_null_market_estimate = real_estate_data[real_estate_data[\"MarketEstimate\"].notnull()]\n",
    "\n",
    "avg_market_minus_list = (\n",
    "    real_estate_data[\"MarketEstimate\"] - real_estate_data[\"ListedPrice\"]\n",
    ").median()\n",
    "avg_market_minus_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16705,\n",
       " State                0\n",
       " City                 0\n",
       " Street               0\n",
       " Zipcode              0\n",
       " Bedroom              9\n",
       " Bathroom            24\n",
       " Area                 0\n",
       " PPSq                 0\n",
       " LotArea            611\n",
       " MarketEstimate    1308\n",
       " RentEstimate         0\n",
       " Latitude             0\n",
       " Longitude            0\n",
       " ListedPrice          0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all rows without a Rent Estimate as this value is vital to my analysis.\n",
    "\n",
    "real_estate_data = real_estate_data[real_estate_data[\"RentEstimate\"].notnull()]\n",
    "\n",
    "len(real_estate_data), real_estate_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State               0\n",
       "City                0\n",
       "Street              0\n",
       "Zipcode             0\n",
       "Bedroom             9\n",
       "Bathroom           24\n",
       "Area                0\n",
       "PPSq                0\n",
       "LotArea           611\n",
       "MarketEstimate      0\n",
       "RentEstimate        0\n",
       "Latitude            0\n",
       "Longitude           0\n",
       "ListedPrice         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update market estimates with the average difference between\n",
    "for index, row in real_estate_data.iterrows():\n",
    "    if pd.isna(row[\"MarketEstimate\"]):\n",
    "        real_estate_data.at[index, \"MarketEstimate\"] = (\n",
    "            row[\"ListedPrice\"] + avg_market_minus_list\n",
    "        )\n",
    "\n",
    "real_estate_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             0\n",
       "City              0\n",
       "Street            0\n",
       "Zipcode           0\n",
       "Bedroom           0\n",
       "Bathroom          0\n",
       "Area              0\n",
       "PPSq              0\n",
       "LotArea           0\n",
       "MarketEstimate    0\n",
       "RentEstimate      0\n",
       "Latitude          0\n",
       "Longitude         0\n",
       "ListedPrice       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate bed, bath, and lot area based on the median area for the given state.\n",
    "\n",
    "\n",
    "def get_median_for_row(row: pd.Series, df: pd.DataFrame, area_offset=200):\n",
    "    area = row[\"Area\"]\n",
    "    filtered_df = df[df[\"State\"].eq(row[\"State\"])].query(\n",
    "        f\"Area <= {area + area_offset} or Area >= {area - area_offset}\"\n",
    "    )\n",
    "    median_bed = filtered_df[\"Bedroom\"].median()\n",
    "    median_bath = filtered_df[\"Bathroom\"].median()\n",
    "    median_lot = filtered_df[\"LotArea\"].median()\n",
    "    return median_bed, median_bath, median_lot\n",
    "\n",
    "\n",
    "for index, row in real_estate_data.iterrows():\n",
    "    if pd.isna(row[\"Bedroom\"]) or pd.isna(row[\"Bathroom\"]) or pd.isna(row[\"LotArea\"]):\n",
    "        if pd.isna(row[\"Bedroom\"]):\n",
    "            median_bed, _, _ = get_median_for_row(row, real_estate_data)\n",
    "            real_estate_data.at[index, \"Bedroom\"] = median_bed\n",
    "        if pd.isna(row[\"Bathroom\"]):\n",
    "            _, median_bath, _ = get_median_for_row(row, real_estate_data)\n",
    "            real_estate_data.at[index, \"Bathroom\"] = median_bath\n",
    "        if pd.isna(row[\"LotArea\"]):\n",
    "            _, _, median_lot = get_median_for_row(row, real_estate_data)\n",
    "            real_estate_data.at[index, \"LotArea\"] = median_lot\n",
    "\n",
    "real_estate_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36571', '35043', '35811', ..., '82649', '83112', '82932'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert zipcodes to string data as the number representation does not provide much value.\n",
    "\n",
    "\n",
    "def zip_to_zip_str(numeric_zip: float):\n",
    "    rounded_zip = int(numeric_zip)\n",
    "    return str(rounded_zip).zfill(5)\n",
    "\n",
    "\n",
    "real_estate_data[\"Zipcode\"] = real_estate_data[\"Zipcode\"].apply(zip_to_zip_str)\n",
    "\n",
    "real_estate_data[\"Zipcode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListedPrice</th>\n",
       "      <th>MarketEstimate</th>\n",
       "      <th>RentEstimate</th>\n",
       "      <th>AnnualPropertyTaxEstimate</th>\n",
       "      <th>MonthlyMortgageEstimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239900.0</td>\n",
       "      <td>240600.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>986.46</td>\n",
       "      <td>1438.321710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335000.0</td>\n",
       "      <td>336200.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1378.42</td>\n",
       "      <td>2008.494259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>222700.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>913.07</td>\n",
       "      <td>1498.876313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151000.0</td>\n",
       "      <td>150500.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>617.05</td>\n",
       "      <td>905.321293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>239000.0</td>\n",
       "      <td>238400.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>977.44</td>\n",
       "      <td>1432.925755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ListedPrice  MarketEstimate  RentEstimate  AnnualPropertyTaxEstimate  \\\n",
       "0     239900.0        240600.0        1599.0                     986.46   \n",
       "3     335000.0        336200.0        1932.0                    1378.42   \n",
       "4     250000.0        222700.0        1679.0                     913.07   \n",
       "5     151000.0        150500.0        1385.0                     617.05   \n",
       "6     239000.0        238400.0        2125.0                     977.44   \n",
       "\n",
       "   MonthlyMortgageEstimate  \n",
       "0              1438.321710  \n",
       "3              2008.494259  \n",
       "4              1498.876313  \n",
       "5               905.321293  \n",
       "6              1432.925755  "
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.const import property_tax_rates\n",
    "\n",
    "# Calculating the additional features:\n",
    "\n",
    "real_estate_data[\"AnnualPropertyTaxEstimate\"] = real_estate_data[\n",
    "    \"MarketEstimate\"\n",
    "] * real_estate_data[\"State\"].map(property_tax_rates)\n",
    "\n",
    "\n",
    "# Estimated Monthly Mortgage - assuming a 30-year fixed mortgage at 6% interest rate.\n",
    "interest_rate = 0.06 / 12\n",
    "loan_term = 30 * 12  # 30 years fixed rate loan.\n",
    "real_estate_data[\"MonthlyMortgageEstimate\"] = (\n",
    "    real_estate_data[\"ListedPrice\"] * interest_rate * (1 + interest_rate) ** loan_term\n",
    ") / ((1 + interest_rate) ** loan_term - 1)\n",
    "\n",
    "real_estate_data[\n",
    "    [\n",
    "        \"ListedPrice\",\n",
    "        \"MarketEstimate\",\n",
    "        \"RentEstimate\",\n",
    "        \"AnnualPropertyTaxEstimate\",\n",
    "        \"MonthlyMortgageEstimate\",\n",
    "    ]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16705,\n",
       " GoodInvestment\n",
       " 0    10523\n",
       " 1     6182\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this exercise I am going to populate the \"GoodInvestment\" field with 1 when the Rent price exceeds the annual cost of the home.\n",
    "\n",
    "real_estate_data[\"AnnualCost\"] = (\n",
    "    real_estate_data[\"MonthlyMortgageEstimate\"] * 12\n",
    ") + real_estate_data[\"AnnualPropertyTaxEstimate\"]\n",
    "real_estate_data[\"AnnualIncome\"] = real_estate_data[\"RentEstimate\"] * 12\n",
    "\n",
    "real_estate_data[\"GoodInvestment\"] = real_estate_data.apply(\n",
    "    lambda row: 1 if row[\"AnnualIncome\"] > row[\"AnnualCost\"] else 0, axis=1\n",
    ")\n",
    "\n",
    "len(real_estate_data), real_estate_data[\"GoodInvestment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function which creates testing and training data drops fields that should not be included in the analysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_test(df: pd.DataFrame):\n",
    "    X = df.drop(\n",
    "        [\n",
    "            \"GoodInvestment\",\n",
    "            \"AnnualCost\",\n",
    "            \"AnnualIncome\",\n",
    "            \"RentEstimate\",\n",
    "            \"MonthlyMortgageEstimate\",\n",
    "            \"AnnualPropertyTaxEstimate\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    y = df[\"GoodInvestment\"]\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  150000,\n",
       "  200000,\n",
       "  250000,\n",
       "  300000,\n",
       "  350000,\n",
       "  400000,\n",
       "  450000,\n",
       "  500000,\n",
       "  600000,\n",
       "  750000,\n",
       "  1000000,\n",
       "  2500000,\n",
       "  5000000,\n",
       "  10000000,\n",
       "  76000001.0],\n",
       " [0, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 5000, 7500, 10000, 99991.0],\n",
       " [0, 0.11, 0.17, 0.23, 0.35, 0.5, 1, 1.5, 3, 10, 701.0],\n",
       " array([ 0.        ,  0.75      ,  1.        ,  1.10000002,  1.20000005,\n",
       "         1.5       ,  1.75      ,  2.        ,  2.0999999 ,  2.20000005,\n",
       "         2.5       ,  3.        ,  3.0999999 ,  3.5       ,  4.        ,\n",
       "         4.0999999 ,  4.5       ,  5.        ,  6.        ,  7.        ,\n",
       "         8.        ,  9.        , 10.        , 11.        , 12.        ,\n",
       "        13.        , 14.        , 17.        , 23.        , 25.        ]),\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 16., 18.]))"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decisions trees sometimes perform better when continuous data data is binned. We will bin values like areas, beds, bathrooms, and prices.\n",
    "\n",
    "area_bins = [\n",
    "    0,\n",
    "    1000,\n",
    "    1500,\n",
    "    2000,\n",
    "    2500,\n",
    "    3000,\n",
    "    3500,\n",
    "    4000,\n",
    "    5000,\n",
    "    7500,\n",
    "    10000,\n",
    "    real_estate_data[\"Area\"].max() + 1,\n",
    "]\n",
    "area_labels = [\n",
    "    \"0-1000 sqft\",\n",
    "    \"1000-1500 sqft\",\n",
    "    \"1500-2000 sqft\",\n",
    "    \"2000-2500 sqft\",\n",
    "    \"2500-3000 sqft\",\n",
    "    \"3000-3500 sqft\",\n",
    "    \"3500-4000 sqft\",\n",
    "    \"4000-5000 sqft\",\n",
    "    \"5000-7500 sqft\",\n",
    "    \"7500-10000 sqft\",\n",
    "    \"10000+ sqft\",\n",
    "]\n",
    "\n",
    "price_bins = [\n",
    "    0,\n",
    "    150_000,\n",
    "    200_000,\n",
    "    250_000,\n",
    "    300_000,\n",
    "    350_000,\n",
    "    400_000,\n",
    "    450_000,\n",
    "    500_000,\n",
    "    600_000,\n",
    "    750_000,\n",
    "    1_000_000,\n",
    "    2_500_000,\n",
    "    5_000_000,\n",
    "    10_000_000,\n",
    "    real_estate_data[\"ListedPrice\"].max() + 1,\n",
    "]\n",
    "price_labels = [\n",
    "    \"0-150k\",\n",
    "    \"150k-200k\",\n",
    "    \"200k-250k\",\n",
    "    \"250k-300k\",\n",
    "    \"300k-350k\",\n",
    "    \"350k-400k\",\n",
    "    \"400k-450k\",\n",
    "    \"450k-500k\",\n",
    "    \"500k-600k\",\n",
    "    \"600k-750k\",\n",
    "    \"750k-1m\",\n",
    "    \"1m-2m\",\n",
    "    \"2.5m-5m\",\n",
    "    \"5m-10m\",\n",
    "    \"10m+\",\n",
    "]\n",
    "\n",
    "lot_bins = [\n",
    "    0,\n",
    "    0.11,\n",
    "    0.17,\n",
    "    0.23,\n",
    "    0.35,\n",
    "    0.5,\n",
    "    1,\n",
    "    1.5,\n",
    "    3,\n",
    "    10,\n",
    "    real_estate_data[\"LotArea\"].max() + 1,\n",
    "]\n",
    "lot_labels = [\n",
    "    \"0-0.11 acres\",\n",
    "    \"0.11-0.17 acres\",\n",
    "    \"0.17-0.23 acres\",\n",
    "    \"0.23-0.35 acres\",\n",
    "    \"0.35-0.5 acres\",\n",
    "    \"0.5-1 acres\",\n",
    "    \"1-1.5 acres\",\n",
    "    \"1.5-3 acres\",\n",
    "    \"3-10 acres\",\n",
    "    \"10+ acres\",\n",
    "]\n",
    "\n",
    "bed_bins = [0] + real_estate_data[\"Bathroom\"].sort_values().unique()\n",
    "bed_labels = [str(bed) for bed in bed_bins]\n",
    "bed_labels.pop(0)\n",
    "\n",
    "bath_bins = [0] + real_estate_data[\"Bedroom\"].sort_values().unique()\n",
    "bath_labels = [str(bath) for bath in bath_bins]\n",
    "bath_labels.pop(0)\n",
    "\n",
    "price_bins, price_labels, area_bins, area_labels, lot_bins, lot_labels, bed_bins, bed_labels, bath_bins, bath_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset A: No binning at all.\n",
    "\n",
    "STRING_FIELDS = [\"State\", \"City\", \"Zipcode\", \"Street\"]\n",
    "\n",
    "data_a = pd.get_dummies(real_estate_data, columns=STRING_FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset B: Use all bins.\n",
    "\n",
    "data_b = real_estate_data.copy()\n",
    "\n",
    "data_b[\"ListedPrice_Binned\"] = pd.cut(\n",
    "    data_b[\"ListedPrice\"], bins=price_bins, labels=price_labels\n",
    ")\n",
    "data_b[\"Area_Binned\"] = pd.cut(data_b[\"Area\"], bins=area_bins, labels=area_labels)\n",
    "data_b[\"Bedroom_Binned\"] = pd.cut(data_b[\"Bedroom\"], bins=bed_bins, labels=bed_labels)\n",
    "data_b[\"Bathroom_Binned\"] = pd.cut(\n",
    "    data_b[\"Bathroom\"], bins=bath_bins, labels=bath_labels\n",
    ")\n",
    "data_b[\"LotArea_Binned\"] = pd.cut(data_b[\"LotArea\"], bins=lot_bins, labels=lot_labels)\n",
    "\n",
    "data_b = pd.get_dummies(\n",
    "    data_b.drop([\"ListedPrice\", \"Area\", \"Bathroom\", \"Bedroom\", \"LotArea\"], axis=1),\n",
    "    columns=STRING_FIELDS\n",
    "    + [\n",
    "        \"ListedPrice_Binned\",\n",
    "        \"Area_Binned\",\n",
    "        \"Bedroom_Binned\",\n",
    "        \"Bathroom_Binned\",\n",
    "        \"LotArea_Binned\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset C: Area binned only.\n",
    "\n",
    "data_c = real_estate_data.copy()\n",
    "\n",
    "data_c[\"Area_Binned\"] = pd.cut(data_c[\"Area\"], bins=area_bins, labels=area_labels)\n",
    "data_c[\"LotArea_Binned\"] = pd.cut(data_c[\"LotArea\"], bins=lot_bins, labels=lot_labels)\n",
    "\n",
    "data_c = pd.get_dummies(\n",
    "    data_c.drop([\"Area\", \"LotArea\"], axis=1),\n",
    "    columns=STRING_FIELDS + [\"Area_Binned\", \"LotArea_Binned\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset D: Only price binned.\n",
    "\n",
    "data_d = real_estate_data.copy()\n",
    "\n",
    "data_d[\"ListedPrice_Binned\"] = pd.cut(\n",
    "    data_d[\"ListedPrice\"], bins=price_bins, labels=price_labels\n",
    ")\n",
    "\n",
    "data_d = pd.get_dummies(\n",
    "    data_d.drop([\"ListedPrice\"], axis=1), columns=STRING_FIELDS + [\"ListedPrice_Binned\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset A accuracy: 0.8216102963184675\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot cast interval[float64, right] dtype to float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/interval.py:1015\u001b[0m, in \u001b[0;36mIntervalArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/base.py:722\u001b[0m, in \u001b[0;36mExtensionArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaArray\u001b[38;5;241m.\u001b[39m_from_sequence(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'pandas._libs.interval.Interval'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:591\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     new_cats \u001b[38;5;241m=\u001b[39m \u001b[43mnew_cats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39m_na_value\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/interval.py:1018\u001b[0m, in \u001b[0;36mIntervalArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   1017\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast IntervalArray to dtype float32",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[651], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset A accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_and_evaluate(data_a)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset B accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_b\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset C accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_and_evaluate(data_c)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset D accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_and_evaluate(data_d)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[651], line 14\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     11\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test(data)\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     16\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/tree/_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/tree/_classes.py:252\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    248\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    249\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m )\n\u001b[1;32m    251\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 252\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_missing_values_in_feature_mask(X)\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:645\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[1;32m    644\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[0;32m--> 645\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[1;32m    647\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/validation.py:875\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 875\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/generic.py:6637\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6631\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6632\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6633\u001b[0m     ]\n\u001b[1;32m   6635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6636\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6637\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6638\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/internals/managers.py:431\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    429\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/internals/managers.py:364\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    367\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:602\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;167;01mTypeError\u001b[39;00m,  \u001b[38;5;66;03m# downstream error msg for CategoricalIndex is misleading\u001b[39;00m\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[1;32m    600\u001b[0m     ):\n\u001b[1;32m    601\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dtype to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 602\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    604\u001b[0m     result \u001b[38;5;241m=\u001b[39m take_nd(\n\u001b[1;32m    605\u001b[0m         new_cats, ensure_platform_int(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes), fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m    606\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot cast interval[float64, right] dtype to float32"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Train the decision tree on all of the datasets and compare the accuracy.\n",
    "\n",
    "\n",
    "def train_and_evaluate(data: pd.DateOffset):\n",
    "    X_train, X_test, y_train, y_test = train_test(data)\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(f\"Dataset A accuracy: {train_and_evaluate(data_a)}\")\n",
    "print(f\"Dataset B accuracy: {train_and_evaluate(data_b)}\")\n",
    "print(f\"Dataset C accuracy: {train_and_evaluate(data_c)}\")\n",
    "print(f\"Dataset D accuracy: {train_and_evaluate(data_d)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
